{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Tue Apr 21 11:10:11 2020\n",
    "\n",
    "@author: Deeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.18.4)\n",
      "Requirement already satisfied: torchsummary in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.18.4)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: torch==1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.3.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (6.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchsummary\n",
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm # Displays a progress bar\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,models, transforms\n",
    "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
    "from data_gen import Dataset\n",
    "from augment import Augmentations as aug\n",
    "from visualization  import visualizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset and train, val, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "num_classes = 2\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "datacsv = pd.read_csv(\"data.csv\")\n",
    "\n",
    "cv_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------Data Augmentation--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_aug = dict(datacsv)\n",
    "data_base_aug[\"image\"] = list(data_base_aug[\"image\"])\n",
    "data_base_aug[\"label\"] = list(data_base_aug[\"label\"])\n",
    "\n",
    "rot = aug()\n",
    "for k in range(len(data_base_aug[\"image\"])):\n",
    "    result = rot.rotate_append(data_base_aug[\"image\"][k],data_base_aug[\"label\"][k])\n",
    "    datacsv = datacsv.append(result,ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------Create dataset generator-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 744, 508]             456\n",
      "         MaxPool2d-2          [-1, 6, 372, 254]               0\n",
      "            Conv2d-3         [-1, 12, 368, 250]           1,812\n",
      "         MaxPool2d-4         [-1, 12, 184, 125]               0\n",
      "            Conv2d-5          [-1, 6, 180, 122]           1,446\n",
      "         MaxPool2d-6            [-1, 6, 90, 61]               0\n",
      "            Conv2d-7            [-1, 3, 84, 58]             507\n",
      "         MaxPool2d-8            [-1, 3, 42, 29]               0\n",
      "            Linear-9                   [-1, 32]         116,960\n",
      "           Linear-10                    [-1, 2]              66\n",
      "================================================================\n",
      "Total params: 121,247\n",
      "Trainable params: 121,247\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.38\n",
      "Forward/backward pass size (MB): 33.55\n",
      "Params size (MB): 0.46\n",
      "Estimated Total Size (MB): 38.40\n",
      "----------------------------------------------------------------\n",
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████████▉                                                                                  | 7/25 [00:19<00:50,  2.80s/it]"
     ]
    }
   ],
   "source": [
    "for cv in range(1):\n",
    "    x_train,x_test =tts(datacsv[\"image\"],test_size=1/6, shuffle=True)\n",
    "    partition = {'train':list(x_train),'validation':list(x_test)}\n",
    "    labels = {}\n",
    "    \n",
    "    for k in range(len(datacsv['image'])):\n",
    "        labels['%s'%datacsv['image'][k]] = datacsv['label'][k]\n",
    "        \n",
    "    #####################################################################\n",
    "    \n",
    "    training_set = Dataset(partition[\"train\"],labels)\n",
    "    training_generator = data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    validation_set = Dataset(partition['validation'], labels)\n",
    "    validation_generator = data.DataLoader(validation_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    class Network(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "            self.conv2 = nn.Conv2d(6, 12, 5)\n",
    "            self.conv3 = nn.Conv2d(12, 6, (5,4))\n",
    "            self.conv4 = nn.Conv2d(6, 3, (7,4))\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(3 * 42 * 29, 32)\n",
    "            self.fc2 = nn.Linear(32, num_classes)\n",
    "            \n",
    "    \n",
    "        def forward(self,x):\n",
    "            # TODO: Design your own network, implement forward pass here\n",
    "            x = self.pool(F.relu(self.conv1(x))) #3*748*512 -> 6*744*508 -> 6*372*254\n",
    "            x = self.pool(F.relu(self.conv2(x))) #6*372*254 -> 12*368*250 -> 12*184*125\n",
    "            x = self.pool(F.relu(self.conv3(x))) #12*184*125 -> 6*180*122 -> 6*90*61\n",
    "            x = self.pool(F.relu(self.conv4(x))) #6*90*61-> 3*84*58 -> 3*42*29\n",
    "            x = x.view(-1, 3 * 42 * 29)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            out = F.softmax(self.fc2(x))\n",
    "            #out = F.softmax(self.fc3(x))\n",
    "            return out\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Configure device\n",
    "    model = Network().to(device)\n",
    "    summary(model,(3,748,512))\n",
    "    criterion = nn.CrossEntropyLoss() # Specify the loss layer\n",
    "    optimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.9) # Specify optimizer and assign trainable parameters to it, weight_decay is L2 regularization strength\n",
    "       \n",
    "    \n",
    "    def train(model, training_generator, num_epoch = num_epochs): # Train the model\n",
    "        print(\"Start training...\")\n",
    "        model.train() # Set the model to training mode\n",
    "        for i in range(num_epoch):\n",
    "            running_loss = []\n",
    "            for batch, label in tqdm(training_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad() # Clear gradients from the previous iteration\n",
    "                pred = model(batch) # This will call Network.forward() that you implement\n",
    "                loss = criterion(pred, label) # Calculate the loss\n",
    "                running_loss.append(loss.item())\n",
    "                loss.backward() # Backprop gradients to all tensors in the network\n",
    "                optimizer.step() # Update trainable weights\n",
    "            print(\"Epoch {} loss:{}\".format(i+1,np.mean(running_loss))) # Print the average loss for this epoch\n",
    "        print(\"Done!\")\n",
    "        try:\n",
    "            torch.save(model, \"Trained_model/teeth_model.pth\")\n",
    "            print(\"Model saved!\")\n",
    "        except:\n",
    "            print(\"Could not save model\")\n",
    "    \n",
    "    def evaluate(model, validation_generator): # Evaluate accuracy on validation / test set\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.set_grad_enabled(True): # Do not calculate grident to speed up computation\n",
    "            for batch, label in tqdm(validation_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                pred = model(batch)\n",
    "                correct += (torch.argmax(pred,dim=1)==label).sum().item()\n",
    "                total+=batch_size\n",
    "        acc = correct/total\n",
    "        print(\"Evaluation accuracy: {}\".format(acc))\n",
    "        return acc\n",
    "        \n",
    "    train(model, training_generator, num_epochs)\n",
    "    print(\"Evaluate on validation set...\")\n",
    "    result = evaluate(model, validation_generator)\n",
    "    cv_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean accuracy: %s\"%(np.mean(cv_results)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis=visualizer()\n",
    "vis.plot_filter(layer=model.conv1,single_channel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.conv2,single_channel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.conv3,single_channel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.conv4,single_channel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.fc1,single_channel = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
