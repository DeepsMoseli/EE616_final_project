{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Tue Apr 21 11:10:11 2020\n",
    "\n",
    "@author: Deeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.1)\nRequirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.18.4)\nRequirement already satisfied: torchsummary in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.1)\nRequirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (0.4.2)\nRequirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.18.4)\nRequirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.13.0)\nRequirement already satisfied: torch==1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.3.1)\nRequirement already satisfied: pillow>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (6.2.0)\n"
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchsummary\n",
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm # Displays a progress bar\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,models, transforms\n",
    "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
    "from data_gen import Dataset\n",
    "from augment import Augmentations as aug\n",
    "from visualization  import visualizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset and train, val, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 70\n",
    "num_classes = 2\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "datacsv = pd.read_csv(\"data.csv\")\n",
    "\n",
    "cv_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------Data Augmentation--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_aug = dict(datacsv)\n",
    "data_base_aug[\"image\"] = list(data_base_aug[\"image\"])\n",
    "data_base_aug[\"label\"] = list(data_base_aug[\"label\"])\n",
    "\n",
    "rot = aug()\n",
    "for k in range(len(data_base_aug[\"image\"])):\n",
    "    result = rot.rotate_append(data_base_aug[\"image\"][k],data_base_aug[\"label\"][k])\n",
    "    datacsv = datacsv.append(result,ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------Create dataset generator-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1          [-1, 6, 744, 508]             456\n         AvgPool2d-2          [-1, 6, 372, 254]               0\n            Conv2d-3         [-1, 12, 368, 250]           1,812\n         MaxPool2d-4         [-1, 12, 184, 125]               0\n            Conv2d-5          [-1, 6, 180, 122]           1,446\n         AvgPool2d-6            [-1, 6, 90, 61]               0\n            Conv2d-7            [-1, 3, 84, 58]             507\n         MaxPool2d-8            [-1, 3, 42, 29]               0\n            Linear-9                  [-1, 258]         942,990\n           Linear-10                    [-1, 2]             518\n================================================================\nTotal params: 947,729\nTrainable params: 947,729\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 4.38\nForward/backward pass size (MB): 33.55\nParams size (MB): 3.62\nEstimated Total Size (MB): 41.55\n----------------------------------------------------------------\nStart training...\n  0%|          | 0/75 [00:08<?, ?it/s]\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 441600000 bytes. Buy new RAM!\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e471adde4b9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Evaluate on validation set...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e471adde4b9a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, training_generator, num_epoch)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Clear gradients from the previous iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# This will call Network.forward() that you implement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Calculate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mrunning_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e471adde4b9a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;31m# TODO: Design your own network, implement forward pass here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoolav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#3*748*512 -> 6*744*508 -> 6*372*254\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#6*372*254 -> 12*368*250 -> 12*184*125\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoolav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#12*184*125 -> 6*180*122 -> 6*90*61\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#6*90*61-> 3*84*58 -> 3*42*29\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 441600000 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "for cv in range(3):\n",
    "    x_train,x_test =tts(datacsv[\"image\"],test_size=1/6, shuffle=True)\n",
    "    partition = {'train':list(x_train),'validation':list(x_test)}\n",
    "    labels = {}\n",
    "    \n",
    "    for k in range(len(datacsv['image'])):\n",
    "        labels['%s'%datacsv['image'][k]] = datacsv['label'][k]\n",
    "        \n",
    "    #####################################################################\n",
    "    \n",
    "    training_set = Dataset(partition[\"train\"],labels)\n",
    "    training_generator = data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    validation_set = Dataset(partition['validation'], labels)\n",
    "    validation_generator = data.DataLoader(validation_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    class Network(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            # TODO: Design your own network, define layers here.\n",
    "            # Here We provide a sample of two-layer fully-connected network.\n",
    "            # Your solution, however, should contain convolutional layers.\n",
    "            # Refer to PyTorch documentations of torch.nn to pick your layers. (https://pytorch.org/docs/stable/nn.html)\n",
    "            # Some common Choices are: Linear, Conv2d, ReLU, MaxPool2d, AvgPool2d, Dropout\n",
    "            # If you have many layers, consider using nn.Sequential() to simplify your code\n",
    "            # self.fc1 = nn.Linear(28*28, 8) # from 28x28 input image to hidden layer of size 256\n",
    "            # self.fc2 = nn.Linear(8,10) # from hidden layer to 10 class scores\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "            self.conv2 = nn.Conv2d(6, 12, 5)\n",
    "            self.conv3 = nn.Conv2d(12, 6, (5,4))\n",
    "            self.conv4 = nn.Conv2d(6, 3, (7,4))\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.poolav = nn.AvgPool2d(2,2)\n",
    "            self.poollast = nn.MaxPool2d(3, 2) \n",
    "            self.fc1 = nn.Linear(3 * 42 * 29, 258)\n",
    "            self.fc2 = nn.Linear(258, num_classes)\n",
    "            \n",
    "    \n",
    "        def forward(self,x):\n",
    "            # TODO: Design your own network, implement forward pass here\n",
    "            x = self.poolav(F.relu(self.conv1(x))) #3*748*512 -> 6*744*508 -> 6*372*254\n",
    "            x = self.pool(F.relu(self.conv2(x))) #6*372*254 -> 12*368*250 -> 12*184*125\n",
    "            x = self.poolav(F.relu(self.conv3(x))) #12*184*125 -> 6*180*122 -> 6*90*61\n",
    "            x = self.pool(F.relu(self.conv4(x))) #6*90*61-> 3*84*58 -> 3*42*29\n",
    "            x = x.view(-1, 3 * 42 * 29)\n",
    "            x = F.dropout(F.relu(self.fc1(x)),0.2)\n",
    "            out = F.softmax(self.fc2(x))\n",
    "            #out = F.softmax(self.fc3(x))\n",
    "            return out\n",
    "    \n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Configure device\n",
    "    model = Network().to(device)\n",
    "    summary(model,(3,748,512))\n",
    "    criterion = nn.CrossEntropyLoss() # Specify the loss layer\n",
    "    optimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.9) # Specify optimizer and assign trainable parameters to it, weight_decay is L2 regularization strength\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(model, training_generator, num_epoch = num_epochs): # Train the model\n",
    "        print(\"Start training...\")\n",
    "        model.train() # Set the model to training mode\n",
    "        for i in range(num_epoch):\n",
    "            running_loss = []\n",
    "            for batch, label in tqdm(training_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad() # Clear gradients from the previous iteration\n",
    "                pred = model(batch) # This will call Network.forward() that you implement\n",
    "                loss = criterion(pred, label) # Calculate the loss\n",
    "                running_loss.append(loss.item())\n",
    "                loss.backward() # Backprop gradients to all tensors in the network\n",
    "                optimizer.step() # Update trainable weights\n",
    "            print(\"Epoch {} loss:{}\".format(i+1,np.mean(running_loss))) # Print the average loss for this epoch\n",
    "        print(\"Done!\")\n",
    "        try:\n",
    "            torch.save(model, \"Trained_model/teeth_model.pth\")\n",
    "            print(\"Model saved!\")\n",
    "        except:\n",
    "            print(\"Could not save model\")\n",
    "    \n",
    "    def evaluate(model, validation_generator): # Evaluate accuracy on validation / test set\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.set_grad_enabled(True): # Do not calculate grident to speed up computation\n",
    "            for batch, label in tqdm(validation_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                pred = model(batch)\n",
    "                correct += (torch.argmax(pred,dim=1)==label).sum().item()\n",
    "                total+=batch_size\n",
    "        acc = correct/total\n",
    "        print(\"Evaluation accuracy: {}\".format(acc))\n",
    "        return acc\n",
    "        \n",
    "    train(model, training_generator, num_epochs)\n",
    "    print(\"Evaluate on validation set...\")\n",
    "    result = evaluate(model, validation_generator)\n",
    "    cv_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean accuracy: %s\"%(np.mean(cv_results)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis=visualizer()\n",
    "vis.plot_filter(layer=model.conv1,single_channel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.conv2,single_channel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.conv3,single_channel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.conv4,single_channel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.fc1,single_channel = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}