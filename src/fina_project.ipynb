{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Tue Apr 21 11:10:11 2020\n",
    "\n",
    "@author: Deeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#!pip install torch\n",
    "#!pip install torchsummary\n",
    "#!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm # Displays a progress bar\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from PIL import Image, ImageFilter\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,models, transforms\n",
    "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
    "from data_gen import Dataset\n",
    "from augment import Augmentations as aug\n",
    "from visualization  import visualizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset and train, val, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "num_classes = 2\n",
    "batch_size = 5\n",
    "num_rotations = 2 #180\n",
    "rotations = [0,180]\n",
    "learning_rate = 0.001\n",
    "image_size = (748,500)\n",
    "resnet_resize = (374,250)\n",
    "datacsv = pd.read_csv(\"data.csv\")\n",
    "cv_results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------Data Augmentation--------\n",
    "\n",
    "Since we only have 119 images, and I want to keep the test set fixed at 20, with exactly 3 examples of class 0, I first split the data into 99 and 20. I then only apply augmentation to the 99 for training. I do not apply this augmentation function to the test data. only the transformations are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ = len(datacsv['image'])\n",
    "train_size = int(all_ *(5/6))\n",
    "test_size = all_-train_size\n",
    "\n",
    "traincsv = datacsv[:train_size]\n",
    "testcsv = datacsv[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_aug = dict(traincsv)\n",
    "data_base_aug[\"image\"] = list(data_base_aug[\"image\"])\n",
    "data_base_aug[\"label\"] = list(data_base_aug[\"label\"])\n",
    "\n",
    "if num_rotations>0:\n",
    "    rot = aug(rotations)\n",
    "    for k in range(len(data_base_aug[\"image\"])):\n",
    "        result = rot.rotate_append(data_base_aug[\"image\"][k],data_base_aug[\"label\"][k])\n",
    "        traincsv = traincsv.append(result,ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------inspect--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = traincsv['image']\n",
    "x_test = testcsv['image']\n",
    "y_train = traincsv['label']\n",
    "y_test = testcsv['label']\n",
    "\n",
    "#x_train,x_test,y_train,y_test =tts(datacsv[\"image\"], datacsv[\"label\"],test_size=1/6, shuffle=False, random_state=42)\n",
    "partition = {'train':list(x_train),'validation':list(x_test)}\n",
    "labels = {}\n",
    "\n",
    "combinedforlabels = traincsv.append(testcsv,ignore_index = True)\n",
    "\n",
    "for k in range(len(combinedforlabels['image'])):\n",
    "    labels['%s'%combinedforlabels['image'][k]] = combinedforlabels['label'][k]\n",
    "\n",
    "print(\"Total original Images: %s\"%all_)\n",
    "print('Train images( after augmentation): %s'%(len(y_train)), ', Test images: %s'%(len(y_test)))\n",
    "print('Train Positives(with augmentation): %s'%(np.sum(y_train)/len(y_train)), ', Test Positives(No augmentation): %s'%(np.sum(y_test)/len(y_test)))\n",
    "print('Total Real dataset positives: %s'%(np.sum(datacsv[\"label\"])/len(datacsv[\"label\"])))\n",
    "\n",
    "view_image = Image.open('Dataset/' + str(int(combinedforlabels[\"image\"][210])) + '.jpg').convert('LA')\n",
    "plt.imshow(view_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------Create dataset generator-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in range(1):\n",
    "    #x_train,x_test =tts(datacsv[\"image\"],test_size=1/6, shuffle=False)\n",
    "    \n",
    "    #####################################################################\n",
    "    \n",
    "    training_set = Dataset(partition[\"train\"],labels, image_size)\n",
    "    training_generator = data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    validation_set = Dataset(partition['validation'], labels, image_size)\n",
    "    validation_generator = data.DataLoader(validation_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    class Network(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.resnet =  torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)\n",
    "            self.num_ftrs = self.resnet.fc.in_features\n",
    "            self.resnet.fc = nn.Linear(self.num_ftrs,8)\n",
    "            self.fc1 = nn.Linear(8, num_classes)\n",
    "            \n",
    "        def forward(self,x):\n",
    "            # TODO: Design your own network, implement forward pass here\n",
    "            x = F.dropout(F.relu(self.resnet(x)),0.2)#3*748*512 -> 6*744*508 -> 6*372*254\n",
    "            out = F.softmax(self.fc1(x))\n",
    "            return out\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Configure device\n",
    "    model = Network().to(device)\n",
    "    \n",
    "    ct = 0 \n",
    "    model_size = len([1 for k in model.children()])\n",
    "    print(\"model components: \", model_size)\n",
    "    for child in model.children():\n",
    "        ct+=1\n",
    "        if ct==1:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad=False\n",
    "    \n",
    "    model.resnet.fc.weight.requires_grad = True\n",
    "    model.resnet.fc.bias.requires_grad = Truee\n",
    "    \n",
    "    #model.resnet.layer4[1].conv2.weight.requires_grad = True\n",
    "    \n",
    "    model.fc1.weight.requires_grad = True\n",
    "    model.fc1.bias.requires_grad = True\n",
    "\n",
    "    \n",
    "    weights = torch.tensor([0.6,0.4])\n",
    "    criterion = nn.CrossEntropyLoss(weight = weights) # Specify the loss layer\n",
    "    optimizer = optim.Adam(model.parameters()) # Specify optimizer and assign trainable parameters to it, weight_decay is L2 regularization strength\n",
    "       \n",
    "    \n",
    "    def train(model, training_generator, num_epoch = num_epochs): # Train the model\n",
    "        print(\"Start training...\")\n",
    "        model.train() # Set the model to training mode\n",
    "        train_val_loss = {'train':[], 'validation':[]}\n",
    "        for i in range(num_epoch):\n",
    "            running_loss = []\n",
    "            accuracy = []\n",
    "            for batch, label in tqdm(training_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad() # Clear gradients from the previous iteration\n",
    "                pred = model(batch) # This will call Network.forward() that you implement\n",
    "                loss = criterion(pred, label) # Calculate the loss\n",
    "                running_loss.append(loss.item())\n",
    "                correct = (torch.argmax(pred,dim=1)==label).sum().item()\n",
    "                accuracy.append(correct/batch_size)\n",
    "                \n",
    "                loss.backward() # Backprop gradients to all tensors in the network\n",
    "                optimizer.step() # Update trainable weights\n",
    "                \n",
    "            val_loss, val_accuracy = evaluate(model, validation_generator)\n",
    "            print(\"Epoch {}   loss:{}   eval_loss:{}   accuracy:{}   eval_accuracy: {}\".format(i+1,np.mean(running_loss), val_loss, np.mean(accuracy),val_accuracy)) # Print the average loss for this epoch\n",
    "            \n",
    "            train_val_loss['train'].append(np.mean(running_loss))\n",
    "            train_val_loss['validation'].append(np.mean(val_loss))\n",
    "            \n",
    "            if (i+1)%10==0 or i==(num_epoch-1):\n",
    "                try:\n",
    "                    torch.save(model, \"Trained_model/teeth_model_%s.pth\"%(i+1))\n",
    "                    print(\"Model saved at Trained _model\")    \n",
    "                except:\n",
    "                    print(\"Could not save model\")\n",
    "        print(\"Done!\")\n",
    "        return train_val_loss\n",
    "\n",
    "\n",
    "    def evaluate(model, validation_generator): # Evaluate accuracy on validation / test set\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_run_loss = []\n",
    "        with torch.set_grad_enabled(True): # Do not calculate grident to speed up computation\n",
    "            for batch, label in tqdm(validation_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                pred = model(batch)\n",
    "                loss = criterion(pred, label).item()\n",
    "                val_run_loss.append(loss)\n",
    "                correct += (torch.argmax(pred,dim=1)==label).sum().item()\n",
    "                total+=batch_size\n",
    "        acc = correct/total\n",
    "        #print(\"Evaluation accuracy: {}\".format(acc))\n",
    "        return (np.mean(loss),acc)\n",
    "    \n",
    "    def predict(model, validation_generator): # Evaluate accuracy on validation / test set\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        results = {'pred':[],'real':[]}\n",
    "        with torch.set_grad_enabled(True): # Do not calculate grident to speed up computation\n",
    "            for batch, label in tqdm(validation_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                pred = model(batch)\n",
    "                pred = torch.argmax(pred,dim=1)\n",
    "                for k in range(len(pred)):\n",
    "                    results['pred'].append(pred[k].item())\n",
    "                    results['real'].append(label[k].item())\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = train(model, training_generator, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = pd.DataFrame(train_history).plot(kind='line',grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_pred = pd.DataFrame(predict(model, validation_generator))\n",
    "print(\"Confusion matrix shows the TP, FP,TN, FN rates of the model\")\n",
    "print(confusion_matrix(see_pred['real'],see_pred['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis=visualizer()\n",
    "vis.plot_filter(layer=model.resnet.conv1,single_channel = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------The END---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model,(3,resnet_resize[0],resnet_resize[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
