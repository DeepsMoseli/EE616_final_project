{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Tue Apr 21 11:10:11 2020\n",
    "\n",
    "@author: Deeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#!pip install torch\n",
    "#!pip install torchsummary\n",
    "#! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm # Displays a progress bar\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,models, transforms\n",
    "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
    "from data_gen import Dataset\n",
    "from augment import Augmentations as aug\n",
    "from visualization  import visualizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset and train, val, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "num_classes = 2\n",
    "batch_size = 16\n",
    "num_rotations = 1 #180\n",
    "learning_rate = 0.001\n",
    "image_size = (748,500)\n",
    "resnet_resize = (224,224)\n",
    "datacsv = pd.read_csv(\"data.csv\")\n",
    "\n",
    "cv_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------Data Augmentation--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_aug = dict(datacsv)\n",
    "data_base_aug[\"image\"] = list(data_base_aug[\"image\"])\n",
    "data_base_aug[\"label\"] = list(data_base_aug[\"label\"])\n",
    "\n",
    "rot = aug()\n",
    "for k in range(len(data_base_aug[\"image\"])):\n",
    "    result = rot.rotate_append(data_base_aug[\"image\"][k],data_base_aug[\"label\"][k])\n",
    "    datacsv = datacsv.append(result,ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------Create dataset generator-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Deeps/.cache\\torch\\hub\\pytorch_vision_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model components:  2\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "           Conv2d-22           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "             ReLU-28          [-1, 128, 28, 28]               0\n",
      "           Conv2d-29          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
      "           Conv2d-31          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "             ReLU-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
      "             ReLU-40          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-41          [-1, 128, 28, 28]               0\n",
      "           Conv2d-42          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "             ReLU-44          [-1, 128, 28, 28]               0\n",
      "           Conv2d-45          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
      "             ReLU-47          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-48          [-1, 128, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 14, 14]             512\n",
      "             ReLU-58          [-1, 256, 14, 14]               0\n",
      "           Conv2d-59          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-60          [-1, 256, 14, 14]             512\n",
      "           Conv2d-61          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-62          [-1, 256, 14, 14]             512\n",
      "             ReLU-63          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-64          [-1, 256, 14, 14]               0\n",
      "           Conv2d-65          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-66          [-1, 256, 14, 14]             512\n",
      "             ReLU-67          [-1, 256, 14, 14]               0\n",
      "           Conv2d-68          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-69          [-1, 256, 14, 14]             512\n",
      "             ReLU-70          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-71          [-1, 256, 14, 14]               0\n",
      "           Conv2d-72          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 14, 14]             512\n",
      "             ReLU-74          [-1, 256, 14, 14]               0\n",
      "           Conv2d-75          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "             ReLU-77          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-78          [-1, 256, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
      "             ReLU-81          [-1, 256, 14, 14]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-85          [-1, 256, 14, 14]               0\n",
      "           Conv2d-86          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "           Conv2d-89          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
      "             ReLU-91          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-92          [-1, 256, 14, 14]               0\n",
      "           Conv2d-93          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "           Conv2d-96          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-97          [-1, 256, 14, 14]             512\n",
      "             ReLU-98          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-99          [-1, 256, 14, 14]               0\n",
      "          Conv2d-100            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-102            [-1, 512, 7, 7]               0\n",
      "          Conv2d-103            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-105            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-107            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-108            [-1, 512, 7, 7]               0\n",
      "          Conv2d-109            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-111            [-1, 512, 7, 7]               0\n",
      "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-114            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-115            [-1, 512, 7, 7]               0\n",
      "          Conv2d-116            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-118            [-1, 512, 7, 7]               0\n",
      "          Conv2d-119            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-121            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                  [-1, 256]         131,328\n",
      "          ResNet-125                  [-1, 256]               0\n",
      "          Linear-126                    [-1, 2]             514\n",
      "================================================================\n",
      "Total params: 21,416,514\n",
      "Trainable params: 2,491,138\n",
      "Non-trainable params: 18,925,376\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 96.29\n",
      "Params size (MB): 81.70\n",
      "Estimated Total Size (MB): 178.56\n",
      "----------------------------------------------------------------\n",
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:04<00:27,  4.54s/it]\n",
      " 29%|████████████████████████                                                            | 2/7 [00:08<00:22,  4.50s/it]\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:13<00:17,  4.41s/it]\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:18<00:13,  4.58s/it]\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:23<00:09,  4.95s/it]\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:28<00:04,  4.76s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:29<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss:0.45570527229990276 accuracy:0.7589285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:04<00:25,  4.27s/it]\n",
      " 29%|████████████████████████                                                            | 2/7 [00:08<00:21,  4.27s/it]\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:12<00:16,  4.24s/it]\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:17<00:12,  4.26s/it]\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:21<00:08,  4.22s/it]\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:25<00:04,  4.25s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:26<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss:0.4111647605895996 accuracy:0.7946428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:04<00:25,  4.27s/it]\n",
      " 29%|████████████████████████                                                            | 2/7 [00:08<00:20,  4.20s/it]\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:12<00:16,  4.16s/it]\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:16<00:12,  4.19s/it]\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:20<00:08,  4.17s/it]\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:25<00:04,  4.23s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:26<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss:0.41126697404044016 accuracy:0.7946428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:04<00:24,  4.06s/it]\n",
      " 29%|████████████████████████                                                            | 2/7 [00:08<00:20,  4.09s/it]\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:12<00:16,  4.15s/it]\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:16<00:12,  4.16s/it]\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:20<00:08,  4.14s/it]\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:25<00:04,  4.26s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:26<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss:0.41113948822021484 accuracy:0.7946428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:04<00:26,  4.47s/it]\n",
      " 29%|████████████████████████                                                            | 2/7 [00:08<00:21,  4.34s/it]\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:12<00:17,  4.31s/it]\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:16<00:12,  4.26s/it]\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:20<00:08,  4.20s/it]\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:25<00:04,  4.19s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:26<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss:0.41089944754328045 accuracy:0.7946428571428571\n",
      "Model saved at\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:04<00:24,  4.09s/it]\n",
      " 29%|████████████████████████                                                            | 2/7 [00:08<00:20,  4.11s/it]\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:12<00:16,  4.10s/it]\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:16<00:12,  4.11s/it]\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:20<00:08,  4.11s/it]\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:24<00:04,  4.10s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:25<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss:0.41060177768979755 accuracy:0.7946428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:04<00:24,  4.10s/it]\n",
      " 29%|████████████████████████                                                            | 2/7 [00:08<00:20,  4.09s/it]\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:12<00:16,  4.09s/it]\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:16<00:12,  4.13s/it]\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:20<00:08,  4.18s/it]\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:24<00:04,  4.18s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:26<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss:0.40887623599597384 accuracy:0.7946428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:04<00:25,  4.22s/it]\n",
      " 29%|████████████████████████                                                            | 2/7 [00:08<00:21,  4.21s/it]\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:12<00:17,  4.26s/it]\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:16<00:12,  4.22s/it]\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:21<00:08,  4.24s/it]\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:25<00:04,  4.24s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:26<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss:0.4059476596968515 accuracy:0.7946428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:04<00:25,  4.20s/it]\n",
      " 29%|████████████████████████                                                            | 2/7 [00:08<00:20,  4.14s/it]\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:12<00:16,  4.15s/it]\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:16<00:12,  4.16s/it]\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:20<00:08,  4.14s/it]\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:24<00:04,  4.11s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:25<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss:0.39979403785296846 accuracy:0.7946428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|████████████                                                                        | 1/7 [00:04<00:25,  4.27s/it]\n",
      " 29%|████████████████████████                                                            | 2/7 [00:08<00:21,  4.30s/it]\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:13<00:17,  4.33s/it]\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:17<00:13,  4.36s/it]\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:22<00:08,  4.45s/it]\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:26<00:04,  4.36s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:27<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss:0.38892765981810434 accuracy:0.8125\n",
      "Model saved at\n",
      "Done!\n",
      "Evaluate on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:03<00:03,  3.18s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "for cv in range(1):\n",
    "    #x_train,x_test =tts(datacsv[\"image\"],test_size=1/6, shuffle=False)\n",
    "    x_train = datacsv['image'][:100]\n",
    "    x_test = datacsv['image'][100:]\n",
    "    partition = {'train':list(x_train),'validation':list(x_test)}\n",
    "    labels = {}\n",
    "    \n",
    "    for k in range(len(datacsv['image'])):\n",
    "        labels['%s'%datacsv['image'][k]] = datacsv['label'][k]\n",
    "        \n",
    "    #####################################################################\n",
    "    \n",
    "    training_set = Dataset(partition[\"train\"],labels, image_size)\n",
    "    training_generator = data.DataLoader(training_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    validation_set = Dataset(partition['validation'], labels, image_size)\n",
    "    validation_generator = data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    class Network(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.resnet =  torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)\n",
    "            self.num_ftrs = self.resnet.fc.in_features\n",
    "            self.resnet.fc = nn.Linear(self.num_ftrs,256)\n",
    "            self.fc1 = nn.Linear(256, num_classes)\n",
    "            \n",
    "        def forward(self,x):\n",
    "            # TODO: Design your own network, implement forward pass here\n",
    "            x = F.dropout(F.relu(self.resnet(x)),0.2) #3*748*512 -> 6*744*508 -> 6*372*254\n",
    "            out = F.softmax(self.fc1(x))\n",
    "            return out\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Configure device\n",
    "    model = Network().to(device)\n",
    "    \n",
    "    ct = 0 \n",
    "    model_size = len([1 for k in model.children()])\n",
    "    print(\"model components: \", model_size)\n",
    "    for child in model.children():\n",
    "        ct+=1\n",
    "        if ct==1:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad=False\n",
    "    \n",
    "    model.resnet.fc.weight.requires_grad = True\n",
    "    model.resnet.fc.bias.requires_grad = True\n",
    "    \n",
    "    #model.resnet.layer4[0].conv1.weight.requires_grad = True\n",
    "    #model.resnet.layer4[1].conv1.weight.requires_grad = True\n",
    "    \n",
    "    #model.resnet.layer4[0].conv2.weight.requires_grad = True\n",
    "    model.resnet.layer4[1].conv2.weight.requires_grad = True\n",
    "    \n",
    "    model.fc1.weight.requires_grad = True\n",
    "    model.fc1.bias.requires_grad = True\n",
    "    \n",
    "    summary(model,(3,resnet_resize[0],resnet_resize[1]))\n",
    "    criterion = nn.CrossEntropyLoss() # Specify the loss layer\n",
    "    optimizer = optim.Adam(model.parameters()) # Specify optimizer and assign trainable parameters to it, weight_decay is L2 regularization strength\n",
    "       \n",
    "    \n",
    "    def train(model, training_generator, num_epoch = num_epochs): # Train the model\n",
    "        print(\"Start training...\")\n",
    "        model.train() # Set the model to training mode\n",
    "        for i in range(num_epoch):\n",
    "            running_loss = []\n",
    "            accuracy = []\n",
    "            for batch, label in tqdm(training_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad() # Clear gradients from the previous iteration\n",
    "                pred = model(batch) # This will call Network.forward() that you implement\n",
    "                loss = criterion(pred, label) # Calculate the loss\n",
    "                running_loss.append(loss.item())\n",
    "                correct = (torch.argmax(pred,dim=1)==label).sum().item()\n",
    "                accuracy.append(correct/batch_size)\n",
    "                loss.backward() # Backprop gradients to all tensors in the network\n",
    "                optimizer.step() # Update trainable weights\n",
    "            print(\"Epoch {} loss:{} accuracy:{}\".format(i+1,np.mean(running_loss),np.mean(accuracy))) # Print the average loss for this epoch\n",
    "            if (i+1)%5==0 or i==(num_epoch-1):\n",
    "                try:\n",
    "                    torch.save(model, \"Trained_model/teeth_model_%s.pth\"%(i+1))\n",
    "                    print(\"Model saved at\")\n",
    "                except:\n",
    "                    print(\"Could not save model\")\n",
    "        print(\"Done!\")\n",
    "\n",
    "    \n",
    "    def evaluate(model, validation_generator): # Evaluate accuracy on validation / test set\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.set_grad_enabled(True): # Do not calculate grident to speed up computation\n",
    "            for batch, label in tqdm(validation_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                pred = model(batch)\n",
    "                correct += (torch.argmax(pred,dim=1)==label).sum().item()\n",
    "                total+=batch_size\n",
    "        acc = correct/total\n",
    "        print(\"Evaluation accuracy: {}\".format(acc))\n",
    "        return acc\n",
    "        \n",
    "    train(model, training_generator, num_epochs)\n",
    "    print(\"Evaluate on validation set...\")\n",
    "    result = evaluate(model, validation_generator)\n",
    "    cv_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean accuracy: %s\"%(np.mean(cv_results)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis=visualizer()\n",
    "vis.plot_filter(layer=model.resnet.conv1,single_channel = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis.plot_filter(layer=model.resnet.layer4[0].conv1,single_channel = True)\n",
    "model.resnet.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.conv3,single_channel = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.conv4,single_channel = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.fc1,single_channel = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
