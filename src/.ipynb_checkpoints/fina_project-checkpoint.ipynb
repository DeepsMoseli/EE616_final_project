{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Tue Apr 21 11:10:11 2020\n",
    "\n",
    "@author: Deeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#!pip install torch\n",
    "#!pip install torchsummary\n",
    "#!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm # Displays a progress bar\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,models, transforms\n",
    "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
    "from data_gen import Dataset\n",
    "from augment import Augmentations as aug\n",
    "from visualization  import visualizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset and train, val, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_classes = 2\n",
    "batch_size = 4\n",
    "num_rotations = 1 #180\n",
    "learning_rate = 0.001\n",
    "image_size = (748,500)\n",
    "resnet_resize = (224,224)\n",
    "datacsv = pd.read_csv(\"data.csv\")\n",
    "cv_results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------Data Augmentation--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_aug = dict(datacsv)\n",
    "data_base_aug[\"image\"] = list(data_base_aug[\"image\"])\n",
    "data_base_aug[\"label\"] = list(data_base_aug[\"label\"])\n",
    "\n",
    "rot = aug()\n",
    "for k in range(len(data_base_aug[\"image\"])):\n",
    "    result = rot.rotate_append(data_base_aug[\"image\"][k],data_base_aug[\"label\"][k])\n",
    "    datacsv = datacsv.append(result,ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------inspect--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = datacsv['image'][:100]\n",
    "#x_test = datacsv['image'][100:]\n",
    "x_train,x_test,y_train,y_test =tts(datacsv[\"image\"],datacsv[\"label\"],test_size=1/6, shuffle=False, random_state=42)\n",
    "partition = {'train':list(x_train),'validation':list(x_test)}\n",
    "labels = {}\n",
    "\n",
    "for k in range(len(datacsv['image'])):\n",
    "    labels['%s'%datacsv['image'][k]] = datacsv['label'][k]\n",
    "\n",
    "print('Train images: %s'%(len(y_train)), ', Test images: %s'%(len(y_test)))\n",
    "print('Train Positives: %s'%(np.sum(y_train)/len(y_train)), ', Test Positives: %s'%(np.sum(y_test)/len(y_test)))\n",
    "print('Total positives: %s'%(np.sum(datacsv[\"label\"])/len(datacsv[\"label\"])))\n",
    "\n",
    "view_image = Image.open('Dataset/' + str(datacsv[\"image\"][10]) + '.jpg').convert('LA')\n",
    "plt.imshow(view_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------Create dataset generator-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in range(1):\n",
    "    #x_train,x_test =tts(datacsv[\"image\"],test_size=1/6, shuffle=False)\n",
    "    \n",
    "    #####################################################################\n",
    "    \n",
    "    training_set = Dataset(partition[\"train\"],labels, image_size)\n",
    "    training_generator = data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    validation_set = Dataset(partition['validation'], labels, image_size)\n",
    "    validation_generator = data.DataLoader(validation_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    class Network(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.resnet =  torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)\n",
    "            self.num_ftrs = self.resnet.fc.in_features\n",
    "            self.resnet.fc = nn.Linear(self.num_ftrs,8)\n",
    "            self.fc1 = nn.Linear(8, num_classes)\n",
    "            \n",
    "        def forward(self,x):\n",
    "            # TODO: Design your own network, implement forward pass here\n",
    "            x = F.dropout(F.relu(self.resnet(x)),0.33) #3*748*512 -> 6*744*508 -> 6*372*254\n",
    "            out = F.softmax(self.fc1(x))\n",
    "            return out\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Configure device\n",
    "    model = Network().to(device)\n",
    "    \n",
    "    ct = 0 \n",
    "    model_size = len([1 for k in model.children()])\n",
    "    print(\"model components: \", model_size)\n",
    "    for child in model.children():\n",
    "        ct+=1\n",
    "        if ct==1:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad=False\n",
    "    \n",
    "    model.resnet.fc.weight.requires_grad = True\n",
    "    model.resnet.fc.bias.requires_grad = True\n",
    "    \n",
    "    #model.resnet.layer4[0].conv1.weight.requires_grad = True\n",
    "    #model.resnet.layer4[1].conv1.weight.requires_grad = True\n",
    "    \n",
    "    #model.resnet.layer4[0].conv2.weight.requires_grad = True\n",
    "    model.resnet.layer4[1].conv2.weight.requires_grad = True\n",
    "    \n",
    "    model.fc1.weight.requires_grad = True\n",
    "    model.fc1.bias.requires_grad = True\n",
    "    \n",
    "    summary(model,(3,resnet_resize[0],resnet_resize[1]))\n",
    "    \n",
    "    weights = torch.tensor([0.4, 0.6])\n",
    "    criterion = nn.CrossEntropyLoss(weight = weights) # Specify the loss layer\n",
    "    optimizer = optim.Adam(model.parameters()) # Specify optimizer and assign trainable parameters to it, weight_decay is L2 regularization strength\n",
    "       \n",
    "    \n",
    "    def train(model, training_generator, num_epoch = num_epochs): # Train the model\n",
    "        print(\"Start training...\")\n",
    "        model.train() # Set the model to training mode\n",
    "        for i in range(num_epoch):\n",
    "            running_loss = []\n",
    "            accuracy = []\n",
    "            for batch, label in tqdm(training_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad() # Clear gradients from the previous iteration\n",
    "                pred = model(batch) # This will call Network.forward() that you implement\n",
    "                loss = criterion(pred, label) # Calculate the loss\n",
    "                running_loss.append(loss.item())\n",
    "                correct = (torch.argmax(pred,dim=1)==label).sum().item()\n",
    "                accuracy.append(correct/batch_size)\n",
    "                loss.backward() # Backprop gradients to all tensors in the network\n",
    "                optimizer.step() # Update trainable weights\n",
    "            print(\"Epoch {} loss:{} accuracy:{}\".format(i+1,np.mean(running_loss),np.mean(accuracy))) # Print the average loss for this epoch\n",
    "            if (i+1)%5==0 or i==(num_epoch-1):\n",
    "                try:\n",
    "                    torch.save(model, \"Trained_model/teeth_model_%s.pth\"%(i+1))\n",
    "                    print(\"Model saved at\")\n",
    "                except:\n",
    "                    print(\"Could not save model\")\n",
    "        print(\"Done!\")\n",
    "\n",
    "    \n",
    "    def evaluate(model, validation_generator): # Evaluate accuracy on validation / test set\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.set_grad_enabled(True): # Do not calculate grident to speed up computation\n",
    "            for batch, label in tqdm(validation_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                pred = model(batch)\n",
    "                correct += (torch.argmax(pred,dim=1)==label).sum().item()\n",
    "                total+=batch_size\n",
    "        acc = correct/total\n",
    "        print(\"Evaluation accuracy: {}\".format(acc))\n",
    "        return acc\n",
    "    \n",
    "    def predict(model, validation_generator): # Evaluate accuracy on validation / test set\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        results = {'pred':[],'real':[]}\n",
    "        with torch.set_grad_enabled(True): # Do not calculate grident to speed up computation\n",
    "            for batch, label in tqdm(validation_generator):\n",
    "                batch = batch.to(device)\n",
    "                label = label.to(device)\n",
    "                pred = model(batch)\n",
    "                for k in range(len(pred)):\n",
    "                    results['pred'].append(pred[k][1].item())\n",
    "                    results['real'].append(label[k].item())\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, training_generator, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on validation set...\")\n",
    "result = evaluate(model, validation_generator)\n",
    "cv_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see_pred = pd.DataFrame(predict(model, validation_generator))\n",
    "see_pred = pd.DataFrame(predict(model, validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean accuracy: %s\"%(np.mean(cv_results)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis=visualizer()\n",
    "vis.plot_filter(layer=model.resnet.conv1,single_channel = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis.plot_filter(layer=model.resnet.layer4[0].conv1,single_channel = True)\n",
    "#model.resnet.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.conv3,single_channel = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.conv4,single_channel = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_filter(layer=model.fc1,single_channel = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
